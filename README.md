# Crawlbase vs Traditional Scrapers: Why API-Based Scraping Wins

We invite you to explore our [blog](https://crawlbase.com/blog/crawlbase-vs-traditional-scrapers-why-api-scraping-wins/) for more details.

## Setting Up Your Coding Environment

Before building the application, youâ€™ll need to set up a basic Python environment. Follow these steps to get started:

1. [Install Python 3](https://kinsta.com/knowledgebase/install-python/#how-to-install-python) on your system.
2. Install the required dependencies by running: 

```bash
python -m pip install -r requirements.txt
```

## Obtaining API Credentials

1. Create an account at [Crawlbase](https://crawlbase.com/signup) and log in.
2. After registration, you will receive 5,000 free requests.
3. Locate and copy your Crawling API [Normal requests token](https://crawlbase.com/dashboard/account/docs).

## Running the Example Scripts

Before running the examples, make sure to replace every instance of:

1. `"<Normal requests token>"` with your [Crawling API Normal requests token](https://crawlbase.com/dashboard/account/docs).
2. `"<JavaScript requests token>"` with your [Crawling API JavaScript requests token](https://crawlbase.com/dashboard/account/docs).

### Example Scripts

- To run the example from the **"Example 1: Basic Page"** section:

```bash
python basic_page.py
```

- To run the example from the **"Example 2: JavaScript Page"** section:

```bash
python javascript_page.py
```

- To run the example from the **"Example 3: Basic Page Using Crawling API"** section:

```bash
python basic_page_using_crawling_api.py
```

Copyright 2025 Crawlbase
